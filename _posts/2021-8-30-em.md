---
layout: post
comments: true
title: "EM 算法"
date: 2021-08-30 12:00:00
tags: ML
typora-root-url: ../..
---

> EM 算法用于求解含隐变量的极大似然估计，先根据当前参数估计隐变量的分布，然后极大化该分布下似然函数的期望，以此得到新的参数估计。

<!--more-->

{:class="table-of-content"}
* TOC
{:toc}
### Nation

- 观测数据：$X=(x_1,x_2,\dots ,x_n)$​
- 参数：$\theta$
- 隐变量：$Z$
- 对数似然：$L(\theta;X)=\log P\left( X\mid \theta \right)$​​

### 极大似然估计

我们的目的是通过观测数据 $X$ 估计参数 $\theta$，常用的方法是极大似然估计：
寻找使得对数似然 $L(\theta;X)=\log P\left( X\mid \theta \right)$
最大的参数 $\theta$.

$$
\begin{aligned}
 L(\theta;X)&=\log P\left( X\mid \theta \right)\\
 &=\log \prod_{i=1}^{n}P(x_i\mid \theta)\\
 &=\sum_{i=1}^{n}\log P(x_i\mid \theta)
\end{aligned}
$$

$$
\theta^{\star}=\mathop{\arg \max}_{\theta}\sum_{i=1}^{n}\log P(x_i\mid \theta)
$$

### 隐变量

但是如果模型中存在隐变量，也就是观测参数由隐变量决定，那么

$$
\begin{aligned}
 L(\theta;X)&=\log P\left( X\mid \theta \right)\\
 &=\log \sum_{Z}P(X,Z\mid\theta)\\
 &=\log \sum_{Z}\prod_{i=1}^{n}P(x_i,Z\mid \theta)
\end{aligned}
$$

这种形式很难直接求出极值，因为我们不知道 $Z$ 的真实分布。

我们可以先假设 $Z$ 服从的分布为 $Z\sim q\left( Z\mid \theta \right)$，于是有：

$$
\begin{aligned}
 \log P\left( X\mid \theta \right) &=\log P\left( X,Z\mid \theta \right) -\log P\left( Z\mid X,\theta \right)\\
 &=\log \frac{P\left( X,Z\mid \theta \right)}{q\left( Z\mid \theta \right)}-\log \frac{P\left( Z\mid X,\theta \right)}{q\left( Z\mid \theta \right)}\\
\end{aligned}
$$

两端关于 $Z\sim q\left( Z\mid \theta \right)$ 同时计算期望：

$$
\begin{aligned}
 \log P\left( X\mid \theta \right) &=\sum_Z{q\left( Z\mid \theta \right) \log \frac{P\left( X,Z\mid \theta \right)}{q\left( Z\mid \theta \right)}}\color{blue}{ -\sum_Z{q\left( Z\mid \theta \right) \log \frac{P\left( Z\mid X,\theta \right)}{q\left( Z\mid \theta \right)}}}\\
 &=\mathop {\mathbb{E}} \limits_{Z\sim q\left( Z\mid \theta \right)}\left[ \log P\left( X,Z\mid \theta \right) \right] \color{green}{ -\sum_Z{q\left( Z\mid \theta \right) \log q\left( Z\mid \theta \right) +\color{blue}{ \mathrm{KL}\left( q\left( Z\mid \theta \right) \parallel P\left( Z\mid X,\theta \right) \right) }}}\\
 &=\mathop {\mathbb{E}} \limits_{Z\sim q\left( Z\mid \theta \right)}\left[ \log P\left( X,Z\mid \theta \right) \right] +\color{green}{ H\left( q\left( Z\mid \theta \right) \right) }+\color{blue}{ \mathrm{KL}\left( q\left( Z\mid \theta \right) \parallel P\left( Z\mid X,\theta \right) \right) }\\
 &=\color{red}{ELBO\left( q,\theta \mid X \right) }+\color{blue}{\mathrm{KL}\left( q\left( Z\mid \theta \right) \parallel P\left( Z\mid X,\theta \right) \right) }\\
\end{aligned}
$$

ELBO 是 evidence lower bound optimization(ELBO)，是 $L\left( \theta \right) $​​ 的一个下界。

### EM 算法


EM 算法重复下面两步：

1. 寻找使得 KL 散度最小的  $q^{(t)}(Z) =P\left( Z\mid X,\theta ^{\left( t \right)} \right) $，使得 ELBO 进一步逼近  $L\left( \theta \right)$.

2. 寻找 $ELBO\left( \theta \mid q^{(t)},X \right) $ 的极大值点作为新参数 $\theta^{(t+1)}$.

#### E 步



$$
L( \theta ) -ELBO( q ,\theta\mid X ) =\color{blue}{ \mathrm{KL}\left( q \parallel P\left( Z\mid X,\theta\right) \right) }
$$

要使 ELBO 逼近  $L\left( \theta \right)$，就要让 KL 散度最小，先通过当前参数 $\theta^{(t)}$ 估计 $q^{(t)}$，得 $q^{(t)}(Z) =P\left( Z\mid X,\theta ^{\left( t \right)} \right)$，于是有：

$$
\begin{aligned}
 L\left( \theta \right) &=\log P\left( X\mid \theta \right)\\
 &=\mathop {\mathbb{E}} \limits_{Z\sim P\left( Z\mid X,\theta ^{\left( t \right)} \right)}\left[ \log P\left( X\mid \theta \right) \right]\\
 &=Q\left( \theta ;\theta ^{\left( t \right)} \right) +\mathrm{KL}\left( P\left( Z\mid X,\theta ^{\left( t \right)} \right) \parallel P\left( Z\mid X,\theta \right) \right)\\
\end{aligned}
$$

这里我们将 $ELBO\left( \theta \mid q^{(t)},X \right)$ 记为 $Q\left( \theta ;\theta ^{\left( t \right)} \right)$：

$$
Q\left( \theta ;\theta ^{\left( t \right)} \right)=\mathop {\mathbb{E}} \limits_{Z\sim P\left( Z\mid X,\theta ^{\left( t \right)} \right)}\left[ \log P\left( X,Z\mid \theta \right) \right] +H\left( P\left( Z\mid X,\theta ^{\left( t \right)} \right) \right)
$$

#### M 步

由于信息熵为常数项，因此最大化 $Q\left( \theta ;\theta ^{\left( t \right)} \right)$ 等价于将对数似然 $\log P ( X,Z\mid \theta )$ 的期望最大化。

$$
\theta ^{\left( t+1 \right)}=\mathop {\mathrm{arg}\max} \limits_{\theta}\,Q\left( \theta ;\theta ^{\left( t \right)} \right) =\mathop {\mathrm{arg}\max} \limits_{\theta}\,\mathop {\mathbb{E}} \limits_{Z\sim P\left( Z\mid X,\theta ^{\left( t \right)} \right)}\left[ \log P\left( X,Z\mid \theta \right) \right]
$$

### EM 算法的单调递增性

> EM 算法的解是逐步更优的。

Proof：

$$
 L\left( \theta \right) =Q\left( \theta ;\theta ^{\left( t \right)} \right) +\mathrm{KL}\left( P\left( Z\mid X,\theta ^{\left( t \right)} \right) \parallel P\left( Z\mid X,\theta \right) \right)\\
$$

显然，$L\left( \theta ^{\left( t+1 \right)} \right) \ge L\left( \theta ^{\left( t \right)} \right) $.

### 关于 EM 的一些思考

$$
\begin{aligned}
 \log P\left( X\mid \theta \right)
  &=\color{red}{ELBO\left( q,\theta \mid X \right) }+\color{blue}{\mathrm{KL}\left( q\left( Z\mid \theta \right) \parallel P\left( Z\mid X,\theta \right) \right) }\\
 &=\mathop {\mathbb{E}} \limits_{Z\sim q\left( Z\mid \theta \right)}\left[ \log P\left( X,Z\mid \theta \right) \right] +\color{green}{ H\left( q\left( Z\mid \theta \right) \right) }+\color{blue}{ \mathrm{KL}\left( q\left( Z\mid \theta \right) \parallel P\left( Z\mid X,\theta \right) \right) }\\
\end{aligned}
$$

EM 算法中先极小化  $\mathrm{KL}\left( q \parallel P\left( Z\mid X,\theta^{(t)} \right) \right)$，将得到的 $q^{(t)}$ 带入到期望中，然后极大化期望。

注意到 $q^{(t)}$ 信息熵那一项被忽略掉了，因为 EM 算法认为 $q^{(t)}$ 确定后其信息熵就是一个常数项。

但是我认为信息熵作为一个正则化项，应当和 KL 散度一起考虑：
$q(Z \mid \theta)$ 是 $Z$ 的真实分布，由于没法直接获得，所以只能暂时用 $P(Z\mid X,\theta^{(t)})$ 来近似代替，
但同时也应该考虑过拟合的风险，加上一个信息熵约束让 $q$ 不至于太复杂，这个想法应该是非常合理的。

> 所以我们需要的 $q^{(t)}$ 应该使 $\mathrm{KL}\left( q\parallel P\left( Z\mid X,\theta ^{(t)} \right) \right) +\color{red}{ H\left( q \right) }$ 最小。

E 步：

$$
q^{(t)}=\mathop{\arg \max}_{q}\,\mathrm{KL}\left( q\parallel P\left( Z\mid X,\theta ^{(t)} \right) \right) + H\left( q \right) 
$$

M 步：

$$
\theta ^{\left( t+1 \right)}=\mathop {\mathrm{arg}\max} \limits_{\theta}\,\mathop {\mathbb{E}} \limits_{Z\sim q^{(t)}} \left[ \log P\left( X,Z\mid \theta \right) \right]
$$

但这样会带来两个问题：

1. 不能证明 $L(\theta^{(t+1)})$ 比 $L(\theta^{(t)})$ 更优。
2. E 步中的 $q^{(t)}$ 难以求解。

关于第一个问题，加了正则项后泛化性更强，但的确没办法保证下一步一定会更优，目前也没法证明一定能收敛，但是从经验角度来说应该效果会更好。

关于第二个问题，如何获得一个合适的 $q^{(t)}$ 是更关键的问题，目前正在思考中。。。



> 在 VAE 和 GAN 中一般都默认 $q(Z)$ 为正态分布，从某种角度来说，这也算是考虑了信息熵约束，因为在均值和方差确定的情况下，正态分布的信息熵是最小的。

